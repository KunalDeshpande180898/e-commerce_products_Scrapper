{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c38e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import time\n",
    "import csv\n",
    "import datetime\n",
    "from selenium import webdriver\n",
    "import datetime\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe73c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurations\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "driver = webdriver.Chrome(\n",
    "    r'//Users/kunaldeshpande/Documents/chromedriver 2')\n",
    "\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/98.0.4758.102 Safari/537.36\",\n",
    "           \"X-Amzn-Trace-Id\": \"Root=1-620b953d-2201315c6de7caf52ed38203\", \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\",\n",
    "           \"Accept-Encoding\": \"gzip, deflate, br\"}\n",
    "\n",
    "column_header = ['Title', 'Price', 'Date', 'URL']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11817d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readB2BSiteLinks(webSiteType):\n",
    "    webSiteLink = \"\"\n",
    "    switch = {\n",
    "        \"Amazon\": r\"/Users/kunaldeshpande/Desktop/project/Scrap/amazon/amazonlinks.csv\"\n",
    "    }\n",
    "    df = pd.read_csv(switch[webSiteType])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3fb6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrapB2BSite(siteLinks):\n",
    "    page = requests.get(siteLinks, headers=headers)\n",
    "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "    formattedSoup = BeautifulSoup(soup.prettify(), \"html.parser\")\n",
    "    try:\n",
    "        title = formattedSoup.find(id='productTitle').get_text()\n",
    "        price_parent = formattedSoup.find('span', 'a-price')\n",
    "        price = price_parent.find('span', 'a-offscreen').text\n",
    "        price = price.strip()[1:]\n",
    "        title = title.strip()\n",
    "        today = datetime.datetime.now().isoformat()\n",
    "        data = [title, price, today, siteLinks]\n",
    "        return data\n",
    "    except AttributeError as e:\n",
    "        print(e)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80d091f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeB2BSiteDataToCsvFile(file_path, data, column_header):\n",
    "    has_header = False\n",
    "    # checking if the csv file contains headers already\n",
    "    if(os.path.isfile(file_path)):\n",
    "        with open(file_path, 'r') as csvfile:\n",
    "            # creating a csv reader object\n",
    "            csvreader = csv.reader(csvfile)\n",
    "            # extracting field names through first row\n",
    "            fields = next(csvreader)\n",
    "            if(len(fields)>0):\n",
    "                has_header = True\n",
    "            csvfile.close()\n",
    "      \n",
    "    with open(file_path, 'a', newline='', encoding='UTF8') as f:\n",
    "        writer = csv.writer(f)\n",
    "        if(not has_header):\n",
    "            writer.writerow(column_header)\n",
    "            has_header = True\n",
    "        writer.writerow(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5de5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the B2B site links\n",
    "b2b_site_links = readB2BSiteLinks(\"Amazon\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf3b875",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(b2b_site_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426af9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for site_links in b2b_site_links['Link']:\n",
    "    #starting the scrapping process\n",
    "    data = scrapB2BSite(site_links)\n",
    "    print(data)\n",
    "    sleepTimeInSeconds = random.randrange(2,4)\n",
    "    time.sleep(sleepTimeInSeconds)\n",
    "    # writing the processed output to a csv file\n",
    "    if(len(data)>0):\n",
    "        writeB2BSiteDataToCsvFile('/Users/kunaldeshpande/Desktop/project/Scrap/29092022.csv', data, column_header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3a39c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bad2660",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36378a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
